{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MZSM98/AppControlEscolarFX/blob/main/Copia_de_Lang_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "yKKZOvtQLsKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxXsJuHGluG6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from os import path\n",
        "import pandas as pd\n",
        "\n",
        "FILE_PATH = \"Languages.xlsx\"\n",
        "\n",
        "def get_dataframe():\n",
        "  if path.isfile(FILE_PATH):\n",
        "    print(\"File Already Uploaded!\")\n",
        "    df = pd.read_excel(FILE_PATH)\n",
        "  else:\n",
        "    print(\"Please introduce, the archive Languages.xlsx\")\n",
        "    print(\"Your file should contain two columns: 1 Language, 2 Phrase\")\n",
        "    try:\n",
        "      files.upload()\n",
        "      df = pd.read_excel(FILE_PATH)\n",
        "      print(\"Data Loaded Successfully\")\n",
        "      print(\"Training Data (First 5 Rows)\")\n",
        "      print(df.head())\n",
        "    except FileNotFoundError:\n",
        "      print(\"Error: File Not Found\")\n",
        "      return [None, True]\n",
        "\n",
        "  return [pd.DataFrame(df), False]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[data, has_failed] = get_dataframe()\n",
        "\n",
        "if has_failed:\n",
        "  exit()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "x = data['Phrase']\n",
        "y = data['Language']\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
        "x_numbers = vectorizer.fit_transform(x)\n",
        "\n",
        "TEST_PHRASES = [\n",
        "  \"A pesar de la tardanza en la entrega, el equipo de investigación presentó el informe final con todos los detalles requeridos, demostrando un esfuerzo extraordinario para cumplir con los objetivos establecidos al comienzo del semestre.\",\n",
        "  \"Si quisieras ver la verdad completa detrás de las noticias que salen en la televisión, deberías aprender a leer entre líneas y a cuestionar la información proporcionada por fuentes oficiales antes de sacar una conclusión definitiva.\",\n",
        "  \"Dovremmo considerare tutte le implicazioni economiche e sociali della nuova legge prima di esprimere un'opinione definitiva, poiché essa potrebbe influenzare il futuro di migliaia di lavoratori nel settore pubblico e privato.\",\n",
        "  \"Mentre il sole tramontava sull'orizzonte, il vecchio marinaio ricordava le sue avventure in alto mare, pensando a quanto la vita fosse cambiata da quando aveva lasciato il suo paese natale molti anni prima.\",\n",
        "  \"The unexpected discovery of ancient artifacts deep within the cave forced archaeologists to re-evaluate the timeline of the early settlements in the region, leading to a major change in the historical narrative.\",\n",
        "  \"It is absolutely crucial to maintain clear and respectful communication with all stakeholders throughout the entire development phase of the project, especially when dealing with sensitive data or confidential information.\",\n",
        "  \"Obwohl die Wetterbedingungen äußerst schlecht waren, gelang es der Bergsteigergruppe, den Gipfel zu erreichen und dort die Fahne zu hissen, was ihren außergewöhnlichen Willen und ihre Teamarbeit unter Beweis stellte.\",\n",
        "  \"Die Verantwortung, eine Entscheidung von solch großer Tragweite zu treffen, lastete schwer auf ihren Schultern, da sie wusste, dass die Folgen ihre gesamte Gemeinschaft über die nächsten zehn Jahre hinweg beeinflussen würden.\",\n",
        "  \"Il faudra prendre en considération le point de vue de chacun des participants à la négociation avant de signer le contrat définitif, afin d'assurer une entente juste et équitable pour toutes les parties impliquées dans l'affaire légale.\",\n",
        "  \"L'auteure expliqua que l'inspiration pour son dernier roman lui était venue d'un rêve particulièrement vif et émouvant qu'elle avait fait une nuit d'hiver, lorsque la neige recouvrait entièrement le toit de sa maison isolée.\",\n",
        "]\n",
        "TEST_PHRASES_NUMBERS = vectorizer.transform(TEST_PHRASES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1jGLCYZLxy9",
        "outputId": "ebbffd59-2d9f-4d50-b7cd-42285db30f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Already Uploaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def run_knn_classifier(test_phrases_numbers):\n",
        "  knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
        "  knn_classifier.fit(x_numbers, y)\n",
        "\n",
        "  prediction_knn = knn_classifier.predict(test_phrases_numbers)\n",
        "\n",
        "  print(f\"Prediction KNN: {prediction_knn}\")\n",
        "\n",
        "run_knn_classifier(TEST_PHRASES_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Sw6Zu4aURS",
        "outputId": "09ba9c82-4184-4e00-ee51-e3ec62830318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction KNN: ['Español' 'Español' 'Italiano' 'Italiano' 'English' 'English' 'Deutsch'\n",
            " 'Deutsch' 'Français' 'Français']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def run_decision_tree_classifier(test_phrases_numbers):\n",
        "  print(\"Classifier: Decision Tree\")\n",
        "\n",
        "  tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "  tree_classifier.fit(x_numbers, y)\n",
        "\n",
        "  prediction_tree = tree_classifier.predict(test_phrases_numbers)\n",
        "\n",
        "  print(f\"Prediction Decision Tree: {prediction_tree}\")\n",
        "\n",
        "run_decision_tree_classifier(TEST_PHRASES_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GKvUF38Wb7B",
        "outputId": "02ef35d7-39c7-4354-9863-37601084ef66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Decision Tree\n",
            "Prediction Decision Tree: ['Español' 'Español' 'Italiano' 'Italiano' 'English' 'English' 'Deutsch'\n",
            " 'Deutsch' 'Français' 'Français']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "def run_svm_classifier(test_phrases_numbers):\n",
        "  print(\"Classifier: Support Vector Machine MLP\")\n",
        "\n",
        "  svm_classifier = SVC(kernel='linear')\n",
        "  svm_classifier.fit(x_numbers, y)\n",
        "\n",
        "  prediction_svm = svm_classifier.predict(test_phrases_numbers)\n",
        "\n",
        "  print(f\"Prediction SVM: {prediction_svm}\")\n",
        "\n",
        "run_svm_classifier(TEST_PHRASES_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGwQXVtyb4jb",
        "outputId": "aa0a14f6-1d3f-4f8f-b271-cde528ca4099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Support Vector Machine MLP\n",
            "Prediction SVM: ['Español' 'Español' 'Italiano' 'Italiano' 'English' 'English' 'Deutsch'\n",
            " 'Deutsch' 'Français' 'Français']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def run_mlp_classifier(test_phrases_numbers):\n",
        "  print(\"Classifier: Neural Network MLP\")\n",
        "\n",
        "  mlp_classifier = MLPClassifier(hidden_layer_sizes={10, 10}, max_iter=3000, random_state=42)\n",
        "  mlp_classifier.fit(x_numbers, y)\n",
        "\n",
        "  prediction_mlp = mlp_classifier.predict(test_phrases_numbers)\n",
        "\n",
        "  print(f\"Prediction MLP: {prediction_mlp}\")\n",
        "\n",
        "run_mlp_classifier(TEST_PHRASES_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwCzFkLrcbVc",
        "outputId": "27236a93-c157-4cd9-a43f-4da47b29d77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Neural Network MLP\n",
            "Prediction MLP: ['Español' 'Español' 'Italiano' 'Italiano' 'English' 'English' 'Deutsch'\n",
            " 'Deutsch' 'Français' 'Français']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "def run_lda(test_phrases_numbers):\n",
        "  print(\"Classifier: Linear Discriminant Analysis LDA\")\n",
        "\n",
        "  try:\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    lda.fit(x_numbers.toarray(), y)\n",
        "\n",
        "    prediction_lda = lda.predict(test_phrases_numbers)\n",
        "\n",
        "    print(f\"Prediction LDA: {prediction_lda}\")\n",
        "  except ValueError:\n",
        "    print(\"LDA failed as expected!\");\n",
        "\n",
        "\n",
        "run_lda(TEST_PHRASES_NUMBERS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSdMwhZNdeQ8",
        "outputId": "eb6cef45-7f37-44c7-9212-bff5607317c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Linear Discriminant Analysis LDA\n",
            "Prediction LDA: ['Español' 'Español' 'Italiano' 'Français' 'English' 'English' 'Deutsch'\n",
            " 'Deutsch' 'Français' 'Français']\n"
          ]
        }
      ]
    }
  ]
}